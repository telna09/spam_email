{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing and Training"
      ],
      "metadata": {
        "id": "AWVlbh53vIlh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeapHCdmf_c2",
        "outputId": "23ce5181-919f-4c11-ff27-18de798558ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       965\n",
            "           1       0.94      0.84      0.89       180\n",
            "\n",
            "    accuracy                           0.97      1145\n",
            "   macro avg       0.96      0.92      0.94      1145\n",
            "weighted avg       0.97      0.97      0.97      1145\n",
            "\n",
            "Naive Bayes Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       965\n",
            "           1       0.87      0.91      0.89       180\n",
            "\n",
            "    accuracy                           0.96      1145\n",
            "   macro avg       0.93      0.94      0.93      1145\n",
            "weighted avg       0.96      0.96      0.96      1145\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "from textblob import TextBlob\n",
        "import joblib\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
        "df.columns = ['label', 'text']\n",
        "\n",
        "# Preprocessing\n",
        "def clean_and_correct(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text\n",
        "df['text'] = df['text'].apply(clean_and_correct)\n",
        "\n",
        "# Encode labels\n",
        "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label_num'], test_size=0.2, random_state=42, stratify=df['label_num']\n",
        ")\n",
        "\n",
        "# Weighted upsampling on the training set\n",
        "train_df = pd.DataFrame({'text': X_train, 'label': y_train})\n",
        "count_ham = sum(train_df['label'] == 0)\n",
        "count_spam = sum(train_df['label'] == 1)\n",
        "\n",
        "if count_spam < count_ham:\n",
        "    # Upsample spam\n",
        "    spam_df = train_df[train_df['label'] == 1]\n",
        "    ham_df = train_df[train_df['label'] == 0]\n",
        "    spam_upsampled = spam_df.sample(count_ham, replace=True, random_state=42)\n",
        "    train_balanced = pd.concat([ham_df, spam_upsampled])\n",
        "else:\n",
        "    # Upsample ham (rare, but for completeness)\n",
        "    spam_df = train_df[train_df['label'] == 1]\n",
        "    ham_df = train_df[train_df['label'] == 0]\n",
        "    ham_upsampled = ham_df.sample(count_spam, replace=True, random_state=42)\n",
        "    train_balanced = pd.concat([spam_df, ham_upsampled])\n",
        "\n",
        "train_balanced = train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "X_train_bal = train_balanced['text']\n",
        "y_train_bal = train_balanced['label']\n",
        "\n",
        "# Vectorize text\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_vec = vectorizer.fit_transform(X_train_bal)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train models\n",
        "# 1. Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr.fit(X_train_vec, y_train_bal)\n",
        "\n",
        "# 2. Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_vec, y_train_bal)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(classification_report(y_test, lr.predict(X_test_vec)))\n",
        "\n",
        "print(\"Naive Bayes Results:\")\n",
        "print(classification_report(y_test, nb.predict(X_test_vec)))\n",
        "\n",
        "# Save models and vectorizer\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n",
        "joblib.dump(lr, 'logistic_regression_model.joblib')\n",
        "joblib.dump(nb, 'naive_bayes_model.joblib')\n",
        "\n",
        "# Load and predict\n",
        "def predict_message(model_path, vectorizer_path, message):\n",
        "    vectorizer = joblib.load(vectorizer_path)\n",
        "    model = joblib.load(model_path)\n",
        "    message_clean = clean_and_correct(message)\n",
        "    message_vec = vectorizer.transform([message_clean])\n",
        "    pred = model.predict(message_vec)\n",
        "    return 'spam' if pred[0] == 1 else 'ham'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EXAMPLE"
      ],
      "metadata": {
        "id": "s7VR1sKmvBrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_message('logistic_regression_model.joblib', 'tfidf_vectorizer.joblib', \"win iphone, click this link\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbNdgkerlOJv",
        "outputId": "68d859aa-e46c-4e94-82bb-9515a482e8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    }
  ]
}